{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.407873\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -7.877221 analytic: -7.877221, relative error: 9.319175e-09\n",
      "numerical: 0.199668 analytic: 0.199668, relative error: 7.226508e-08\n",
      "numerical: -6.977982 analytic: -6.977982, relative error: 7.938716e-09\n",
      "numerical: 0.435187 analytic: 0.435187, relative error: 7.615190e-09\n",
      "numerical: -1.707101 analytic: -1.707101, relative error: 1.314020e-08\n",
      "numerical: -2.382712 analytic: -2.382712, relative error: 1.106215e-08\n",
      "numerical: 0.814489 analytic: 0.814489, relative error: 6.146604e-08\n",
      "numerical: -0.280030 analytic: -0.280030, relative error: 4.036338e-08\n",
      "numerical: 1.753540 analytic: 1.753540, relative error: 3.946023e-09\n",
      "numerical: -2.271754 analytic: -2.271754, relative error: 2.362189e-08\n",
      "numerical: -1.753733 analytic: -1.753733, relative error: 1.479032e-08\n",
      "numerical: 3.260002 analytic: 3.260002, relative error: 1.070337e-08\n",
      "numerical: 0.515842 analytic: 0.515842, relative error: 7.462285e-08\n",
      "numerical: 1.341024 analytic: 1.341024, relative error: 5.858117e-09\n",
      "numerical: 1.758607 analytic: 1.758607, relative error: 8.580211e-09\n",
      "numerical: 2.584649 analytic: 2.584649, relative error: 2.309741e-08\n",
      "numerical: -6.300318 analytic: -6.300318, relative error: 1.275252e-08\n",
      "numerical: -2.369091 analytic: -2.369091, relative error: 1.480488e-09\n",
      "numerical: -1.612473 analytic: -1.612473, relative error: 2.698656e-08\n",
      "numerical: 1.904890 analytic: 1.904891, relative error: 2.919846e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.407873e+00 computed in 0.423998s\n",
      "(500, 1)\n",
      "vectorized loss: 2.407873e+00 computed in 0.028801s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000.0\n",
      "10000.0\n",
      "10000.0\n",
      "10000.0\n",
      "10000.0\n",
      "20000.0\n",
      "20000.0\n",
      "20000.0\n",
      "20000.0\n",
      "20000.0\n",
      "30000.0\n",
      "30000.0\n",
      "30000.0\n",
      "30000.0\n",
      "30000.0\n",
      "40000.0\n",
      "40000.0\n",
      "40000.0\n",
      "40000.0\n",
      "40000.0\n",
      "50000.0\n",
      "50000.0\n",
      "50000.0\n",
      "50000.0\n",
      "50000.0\n",
      "11000.0\n",
      "11000.0\n",
      "11000.0\n",
      "11000.0\n",
      "11000.0\n",
      "21000.0\n",
      "21000.0\n",
      "21000.0\n",
      "21000.0\n",
      "21000.0\n",
      "31000.0\n",
      "31000.0\n",
      "31000.0\n",
      "31000.0\n",
      "31000.0\n",
      "41000.0\n",
      "41000.0\n",
      "41000.0\n",
      "41000.0\n",
      "41000.0\n",
      "51000.0\n",
      "51000.0\n",
      "51000.0\n",
      "51000.0\n",
      "51000.0\n",
      "12000.0\n",
      "12000.0\n",
      "12000.0\n",
      "12000.0\n",
      "12000.0\n",
      "22000.0\n",
      "22000.0\n",
      "22000.0\n",
      "22000.0\n",
      "22000.0\n",
      "32000.0\n",
      "32000.0\n",
      "32000.0\n",
      "32000.0\n",
      "32000.0\n",
      "42000.0\n",
      "42000.0\n",
      "42000.0\n",
      "42000.0\n",
      "42000.0\n",
      "52000.0\n",
      "52000.0\n",
      "52000.0\n",
      "52000.0\n",
      "52000.0\n",
      "13000.0\n",
      "13000.0\n",
      "13000.0\n",
      "13000.0\n",
      "13000.0\n",
      "23000.0\n",
      "23000.0\n",
      "23000.0\n",
      "23000.0\n",
      "23000.0\n",
      "33000.0\n",
      "33000.0\n",
      "33000.0\n",
      "33000.0\n",
      "33000.0\n",
      "43000.0\n",
      "43000.0\n",
      "43000.0\n",
      "43000.0\n",
      "43000.0\n",
      "53000.0\n",
      "53000.0\n",
      "53000.0\n",
      "53000.0\n",
      "53000.0\n",
      "14000.0\n",
      "14000.0\n",
      "14000.0\n",
      "14000.0\n",
      "14000.0\n",
      "24000.0\n",
      "24000.0\n",
      "24000.0\n",
      "24000.0\n",
      "24000.0\n",
      "34000.0\n",
      "34000.0\n",
      "34000.0\n",
      "34000.0\n",
      "34000.0\n",
      "44000.0\n",
      "44000.0\n",
      "44000.0\n",
      "44000.0\n",
      "44000.0\n",
      "54000.0\n",
      "54000.0\n",
      "54000.0\n",
      "54000.0\n",
      "54000.0\n",
      "15000.0\n",
      "15000.0\n",
      "15000.0\n",
      "15000.0\n",
      "15000.0\n",
      "25000.0\n",
      "25000.0\n",
      "25000.0\n",
      "25000.0\n",
      "25000.0\n",
      "35000.0\n",
      "35000.0\n",
      "35000.0\n",
      "35000.0\n",
      "35000.0\n",
      "45000.0\n",
      "45000.0\n",
      "45000.0\n",
      "45000.0\n",
      "45000.0\n",
      "55000.0\n",
      "55000.0\n",
      "55000.0\n",
      "55000.0\n",
      "55000.0\n",
      "16000.0\n",
      "16000.0\n",
      "16000.0\n",
      "16000.0\n",
      "16000.0\n",
      "26000.0\n",
      "26000.0\n",
      "26000.0\n",
      "26000.0\n",
      "26000.0\n",
      "36000.0\n",
      "36000.0\n",
      "36000.0\n",
      "36000.0\n",
      "36000.0\n",
      "46000.0\n",
      "46000.0\n",
      "46000.0\n",
      "46000.0\n",
      "46000.0\n",
      "56000.0\n",
      "56000.0\n",
      "56000.0\n",
      "56000.0\n",
      "56000.0\n",
      "17000.0\n",
      "17000.0\n",
      "17000.0\n",
      "17000.0\n",
      "17000.0\n",
      "27000.0\n",
      "27000.0\n",
      "27000.0\n",
      "27000.0\n",
      "27000.0\n",
      "37000.0\n",
      "37000.0\n",
      "37000.0\n",
      "37000.0\n",
      "37000.0\n",
      "47000.0\n",
      "47000.0\n",
      "47000.0\n",
      "47000.0\n",
      "47000.0\n",
      "57000.0\n",
      "57000.0\n",
      "57000.0\n",
      "57000.0\n",
      "57000.0\n",
      "18000.0\n",
      "18000.0\n",
      "18000.0\n",
      "18000.0\n",
      "18000.0\n",
      "28000.0\n",
      "28000.0\n",
      "28000.0\n",
      "28000.0\n",
      "28000.0\n",
      "38000.0\n",
      "38000.0\n",
      "38000.0\n",
      "38000.0\n",
      "38000.0\n",
      "48000.0\n",
      "48000.0\n",
      "48000.0\n",
      "48000.0\n",
      "48000.0\n",
      "58000.0\n",
      "58000.0\n",
      "58000.0\n",
      "58000.0\n",
      "58000.0\n",
      "19000.0\n",
      "19000.0\n",
      "19000.0\n",
      "19000.0\n",
      "19000.0\n",
      "29000.0\n",
      "29000.0\n",
      "29000.0\n",
      "29000.0\n",
      "29000.0\n",
      "39000.0\n",
      "39000.0\n",
      "39000.0\n",
      "39000.0\n",
      "39000.0\n",
      "49000.0\n",
      "49000.0\n",
      "49000.0\n",
      "49000.0\n",
      "49000.0\n",
      "59000.0\n",
      "59000.0\n",
      "59000.0\n",
      "59000.0\n",
      "59000.0\n",
      "lr 1.000000e-07 reg 1.000000e+04 train accuracy: 0.355469 val accuracy: 0.363000\n",
      "lr 1.000000e-07 reg 1.100000e+04 train accuracy: 0.351204 val accuracy: 0.364000\n",
      "lr 1.000000e-07 reg 1.200000e+04 train accuracy: 0.353204 val accuracy: 0.361000\n",
      "lr 1.000000e-07 reg 1.300000e+04 train accuracy: 0.348082 val accuracy: 0.365000\n",
      "lr 1.000000e-07 reg 1.400000e+04 train accuracy: 0.349041 val accuracy: 0.364000\n",
      "lr 1.000000e-07 reg 1.500000e+04 train accuracy: 0.347163 val accuracy: 0.354000\n",
      "lr 1.000000e-07 reg 1.600000e+04 train accuracy: 0.348000 val accuracy: 0.360000\n",
      "lr 1.000000e-07 reg 1.700000e+04 train accuracy: 0.338755 val accuracy: 0.347000\n",
      "lr 1.000000e-07 reg 1.800000e+04 train accuracy: 0.342061 val accuracy: 0.351000\n",
      "lr 1.000000e-07 reg 1.900000e+04 train accuracy: 0.338714 val accuracy: 0.359000\n",
      "lr 1.000000e-07 reg 2.000000e+04 train accuracy: 0.335449 val accuracy: 0.353000\n",
      "lr 1.000000e-07 reg 2.100000e+04 train accuracy: 0.334510 val accuracy: 0.352000\n",
      "lr 1.000000e-07 reg 2.200000e+04 train accuracy: 0.332755 val accuracy: 0.344000\n",
      "lr 1.000000e-07 reg 2.300000e+04 train accuracy: 0.331347 val accuracy: 0.346000\n",
      "lr 1.000000e-07 reg 2.400000e+04 train accuracy: 0.335531 val accuracy: 0.334000\n",
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.325796 val accuracy: 0.343000\n",
      "lr 1.000000e-07 reg 2.600000e+04 train accuracy: 0.323327 val accuracy: 0.338000\n",
      "lr 1.000000e-07 reg 2.700000e+04 train accuracy: 0.327612 val accuracy: 0.341000\n",
      "lr 1.000000e-07 reg 2.800000e+04 train accuracy: 0.323306 val accuracy: 0.351000\n",
      "lr 1.000000e-07 reg 2.900000e+04 train accuracy: 0.329265 val accuracy: 0.344000\n",
      "lr 1.000000e-07 reg 3.000000e+04 train accuracy: 0.319388 val accuracy: 0.332000\n",
      "lr 1.000000e-07 reg 3.100000e+04 train accuracy: 0.323918 val accuracy: 0.338000\n",
      "lr 1.000000e-07 reg 3.200000e+04 train accuracy: 0.316755 val accuracy: 0.334000\n",
      "lr 1.000000e-07 reg 3.300000e+04 train accuracy: 0.320735 val accuracy: 0.330000\n",
      "lr 1.000000e-07 reg 3.400000e+04 train accuracy: 0.322429 val accuracy: 0.337000\n",
      "lr 1.000000e-07 reg 3.500000e+04 train accuracy: 0.318918 val accuracy: 0.336000\n",
      "lr 1.000000e-07 reg 3.600000e+04 train accuracy: 0.312265 val accuracy: 0.333000\n",
      "lr 1.000000e-07 reg 3.700000e+04 train accuracy: 0.314980 val accuracy: 0.333000\n",
      "lr 1.000000e-07 reg 3.800000e+04 train accuracy: 0.319837 val accuracy: 0.333000\n",
      "lr 1.000000e-07 reg 3.900000e+04 train accuracy: 0.316163 val accuracy: 0.326000\n",
      "lr 1.000000e-07 reg 4.000000e+04 train accuracy: 0.303551 val accuracy: 0.331000\n",
      "lr 1.000000e-07 reg 4.100000e+04 train accuracy: 0.309163 val accuracy: 0.330000\n",
      "lr 1.000000e-07 reg 4.200000e+04 train accuracy: 0.316735 val accuracy: 0.321000\n",
      "lr 1.000000e-07 reg 4.300000e+04 train accuracy: 0.306837 val accuracy: 0.330000\n",
      "lr 1.000000e-07 reg 4.400000e+04 train accuracy: 0.313714 val accuracy: 0.327000\n",
      "lr 1.000000e-07 reg 4.500000e+04 train accuracy: 0.308939 val accuracy: 0.319000\n",
      "lr 1.000000e-07 reg 4.600000e+04 train accuracy: 0.307898 val accuracy: 0.322000\n",
      "lr 1.000000e-07 reg 4.700000e+04 train accuracy: 0.309531 val accuracy: 0.320000\n",
      "lr 1.000000e-07 reg 4.800000e+04 train accuracy: 0.301327 val accuracy: 0.315000\n",
      "lr 1.000000e-07 reg 4.900000e+04 train accuracy: 0.310327 val accuracy: 0.321000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.306265 val accuracy: 0.336000\n",
      "lr 1.000000e-07 reg 5.100000e+04 train accuracy: 0.310041 val accuracy: 0.323000\n",
      "lr 1.000000e-07 reg 5.200000e+04 train accuracy: 0.308837 val accuracy: 0.319000\n",
      "lr 1.000000e-07 reg 5.300000e+04 train accuracy: 0.304776 val accuracy: 0.319000\n",
      "lr 1.000000e-07 reg 5.400000e+04 train accuracy: 0.303959 val accuracy: 0.323000\n",
      "lr 1.000000e-07 reg 5.500000e+04 train accuracy: 0.303490 val accuracy: 0.313000\n",
      "lr 1.000000e-07 reg 5.600000e+04 train accuracy: 0.308918 val accuracy: 0.322000\n",
      "lr 1.000000e-07 reg 5.700000e+04 train accuracy: 0.312653 val accuracy: 0.314000\n",
      "lr 1.000000e-07 reg 5.800000e+04 train accuracy: 0.302592 val accuracy: 0.314000\n",
      "lr 1.000000e-07 reg 5.900000e+04 train accuracy: 0.303388 val accuracy: 0.327000\n",
      "lr 3.000000e-07 reg 1.000000e+04 train accuracy: 0.355367 val accuracy: 0.371000\n",
      "lr 3.000000e-07 reg 1.100000e+04 train accuracy: 0.354694 val accuracy: 0.366000\n",
      "lr 3.000000e-07 reg 1.200000e+04 train accuracy: 0.351306 val accuracy: 0.370000\n",
      "lr 3.000000e-07 reg 1.300000e+04 train accuracy: 0.344429 val accuracy: 0.361000\n",
      "lr 3.000000e-07 reg 1.400000e+04 train accuracy: 0.344000 val accuracy: 0.350000\n",
      "lr 3.000000e-07 reg 1.500000e+04 train accuracy: 0.342714 val accuracy: 0.360000\n",
      "lr 3.000000e-07 reg 1.600000e+04 train accuracy: 0.343041 val accuracy: 0.355000\n",
      "lr 3.000000e-07 reg 1.700000e+04 train accuracy: 0.343531 val accuracy: 0.360000\n",
      "lr 3.000000e-07 reg 1.800000e+04 train accuracy: 0.329939 val accuracy: 0.349000\n",
      "lr 3.000000e-07 reg 1.900000e+04 train accuracy: 0.331041 val accuracy: 0.345000\n",
      "lr 3.000000e-07 reg 2.000000e+04 train accuracy: 0.336204 val accuracy: 0.336000\n",
      "lr 3.000000e-07 reg 2.100000e+04 train accuracy: 0.338020 val accuracy: 0.349000\n",
      "lr 3.000000e-07 reg 2.200000e+04 train accuracy: 0.330796 val accuracy: 0.351000\n",
      "lr 3.000000e-07 reg 2.300000e+04 train accuracy: 0.335041 val accuracy: 0.352000\n",
      "lr 3.000000e-07 reg 2.400000e+04 train accuracy: 0.325816 val accuracy: 0.341000\n",
      "lr 3.000000e-07 reg 2.500000e+04 train accuracy: 0.329061 val accuracy: 0.338000\n",
      "lr 3.000000e-07 reg 2.600000e+04 train accuracy: 0.327735 val accuracy: 0.337000\n",
      "lr 3.000000e-07 reg 2.700000e+04 train accuracy: 0.326020 val accuracy: 0.341000\n",
      "lr 3.000000e-07 reg 2.800000e+04 train accuracy: 0.323837 val accuracy: 0.326000\n",
      "lr 3.000000e-07 reg 2.900000e+04 train accuracy: 0.322673 val accuracy: 0.337000\n",
      "lr 3.000000e-07 reg 3.000000e+04 train accuracy: 0.320408 val accuracy: 0.336000\n",
      "lr 3.000000e-07 reg 3.100000e+04 train accuracy: 0.332939 val accuracy: 0.342000\n",
      "lr 3.000000e-07 reg 3.200000e+04 train accuracy: 0.320286 val accuracy: 0.345000\n",
      "lr 3.000000e-07 reg 3.300000e+04 train accuracy: 0.315429 val accuracy: 0.341000\n",
      "lr 3.000000e-07 reg 3.400000e+04 train accuracy: 0.308776 val accuracy: 0.334000\n",
      "lr 3.000000e-07 reg 3.500000e+04 train accuracy: 0.317959 val accuracy: 0.336000\n",
      "lr 3.000000e-07 reg 3.600000e+04 train accuracy: 0.307633 val accuracy: 0.336000\n",
      "lr 3.000000e-07 reg 3.700000e+04 train accuracy: 0.313122 val accuracy: 0.333000\n",
      "lr 3.000000e-07 reg 3.800000e+04 train accuracy: 0.307041 val accuracy: 0.322000\n",
      "lr 3.000000e-07 reg 3.900000e+04 train accuracy: 0.325673 val accuracy: 0.341000\n",
      "lr 3.000000e-07 reg 4.000000e+04 train accuracy: 0.322469 val accuracy: 0.333000\n",
      "lr 3.000000e-07 reg 4.100000e+04 train accuracy: 0.314857 val accuracy: 0.331000\n",
      "lr 3.000000e-07 reg 4.200000e+04 train accuracy: 0.303796 val accuracy: 0.323000\n",
      "lr 3.000000e-07 reg 4.300000e+04 train accuracy: 0.313082 val accuracy: 0.324000\n",
      "lr 3.000000e-07 reg 4.400000e+04 train accuracy: 0.310837 val accuracy: 0.328000\n",
      "lr 3.000000e-07 reg 4.500000e+04 train accuracy: 0.307163 val accuracy: 0.320000\n",
      "lr 3.000000e-07 reg 4.600000e+04 train accuracy: 0.309061 val accuracy: 0.328000\n",
      "lr 3.000000e-07 reg 4.700000e+04 train accuracy: 0.315061 val accuracy: 0.321000\n",
      "lr 3.000000e-07 reg 4.800000e+04 train accuracy: 0.304388 val accuracy: 0.321000\n",
      "lr 3.000000e-07 reg 4.900000e+04 train accuracy: 0.290020 val accuracy: 0.305000\n",
      "lr 3.000000e-07 reg 5.000000e+04 train accuracy: 0.315490 val accuracy: 0.326000\n",
      "lr 3.000000e-07 reg 5.100000e+04 train accuracy: 0.314776 val accuracy: 0.329000\n",
      "lr 3.000000e-07 reg 5.200000e+04 train accuracy: 0.290408 val accuracy: 0.305000\n",
      "lr 3.000000e-07 reg 5.300000e+04 train accuracy: 0.305531 val accuracy: 0.313000\n",
      "lr 3.000000e-07 reg 5.400000e+04 train accuracy: 0.309347 val accuracy: 0.327000\n",
      "lr 3.000000e-07 reg 5.500000e+04 train accuracy: 0.303959 val accuracy: 0.309000\n",
      "lr 3.000000e-07 reg 5.600000e+04 train accuracy: 0.310571 val accuracy: 0.324000\n",
      "lr 3.000000e-07 reg 5.700000e+04 train accuracy: 0.312735 val accuracy: 0.331000\n",
      "lr 3.000000e-07 reg 5.800000e+04 train accuracy: 0.302673 val accuracy: 0.321000\n",
      "lr 3.000000e-07 reg 5.900000e+04 train accuracy: 0.305020 val accuracy: 0.316000\n",
      "lr 5.000000e-07 reg 1.000000e+04 train accuracy: 0.353816 val accuracy: 0.365000\n",
      "lr 5.000000e-07 reg 1.100000e+04 train accuracy: 0.346224 val accuracy: 0.358000\n",
      "lr 5.000000e-07 reg 1.200000e+04 train accuracy: 0.349837 val accuracy: 0.362000\n",
      "lr 5.000000e-07 reg 1.300000e+04 train accuracy: 0.338020 val accuracy: 0.358000\n",
      "lr 5.000000e-07 reg 1.400000e+04 train accuracy: 0.341143 val accuracy: 0.352000\n",
      "lr 5.000000e-07 reg 1.500000e+04 train accuracy: 0.347327 val accuracy: 0.353000\n",
      "lr 5.000000e-07 reg 1.600000e+04 train accuracy: 0.331184 val accuracy: 0.337000\n",
      "lr 5.000000e-07 reg 1.700000e+04 train accuracy: 0.334816 val accuracy: 0.346000\n",
      "lr 5.000000e-07 reg 1.800000e+04 train accuracy: 0.338184 val accuracy: 0.350000\n",
      "lr 5.000000e-07 reg 1.900000e+04 train accuracy: 0.329061 val accuracy: 0.339000\n",
      "lr 5.000000e-07 reg 2.000000e+04 train accuracy: 0.335367 val accuracy: 0.359000\n",
      "lr 5.000000e-07 reg 2.100000e+04 train accuracy: 0.334306 val accuracy: 0.345000\n",
      "lr 5.000000e-07 reg 2.200000e+04 train accuracy: 0.325878 val accuracy: 0.338000\n",
      "lr 5.000000e-07 reg 2.300000e+04 train accuracy: 0.333306 val accuracy: 0.353000\n",
      "lr 5.000000e-07 reg 2.400000e+04 train accuracy: 0.323714 val accuracy: 0.346000\n",
      "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.313163 val accuracy: 0.327000\n",
      "lr 5.000000e-07 reg 2.600000e+04 train accuracy: 0.329224 val accuracy: 0.342000\n",
      "lr 5.000000e-07 reg 2.700000e+04 train accuracy: 0.328122 val accuracy: 0.341000\n",
      "lr 5.000000e-07 reg 2.800000e+04 train accuracy: 0.305102 val accuracy: 0.331000\n",
      "lr 5.000000e-07 reg 2.900000e+04 train accuracy: 0.320082 val accuracy: 0.329000\n",
      "lr 5.000000e-07 reg 3.000000e+04 train accuracy: 0.327286 val accuracy: 0.338000\n",
      "lr 5.000000e-07 reg 3.100000e+04 train accuracy: 0.323143 val accuracy: 0.330000\n",
      "lr 5.000000e-07 reg 3.200000e+04 train accuracy: 0.308633 val accuracy: 0.320000\n",
      "lr 5.000000e-07 reg 3.300000e+04 train accuracy: 0.311694 val accuracy: 0.325000\n",
      "lr 5.000000e-07 reg 3.400000e+04 train accuracy: 0.319041 val accuracy: 0.321000\n",
      "lr 5.000000e-07 reg 3.500000e+04 train accuracy: 0.311469 val accuracy: 0.317000\n",
      "lr 5.000000e-07 reg 3.600000e+04 train accuracy: 0.306388 val accuracy: 0.311000\n",
      "lr 5.000000e-07 reg 3.700000e+04 train accuracy: 0.318265 val accuracy: 0.332000\n",
      "lr 5.000000e-07 reg 3.800000e+04 train accuracy: 0.303306 val accuracy: 0.327000\n",
      "lr 5.000000e-07 reg 3.900000e+04 train accuracy: 0.307857 val accuracy: 0.327000\n",
      "lr 5.000000e-07 reg 4.000000e+04 train accuracy: 0.304857 val accuracy: 0.317000\n",
      "lr 5.000000e-07 reg 4.100000e+04 train accuracy: 0.312735 val accuracy: 0.322000\n",
      "lr 5.000000e-07 reg 4.200000e+04 train accuracy: 0.307571 val accuracy: 0.315000\n",
      "lr 5.000000e-07 reg 4.300000e+04 train accuracy: 0.311510 val accuracy: 0.333000\n",
      "lr 5.000000e-07 reg 4.400000e+04 train accuracy: 0.298776 val accuracy: 0.319000\n",
      "lr 5.000000e-07 reg 4.500000e+04 train accuracy: 0.306245 val accuracy: 0.330000\n",
      "lr 5.000000e-07 reg 4.600000e+04 train accuracy: 0.312143 val accuracy: 0.319000\n",
      "lr 5.000000e-07 reg 4.700000e+04 train accuracy: 0.299469 val accuracy: 0.310000\n",
      "lr 5.000000e-07 reg 4.800000e+04 train accuracy: 0.317490 val accuracy: 0.326000\n",
      "lr 5.000000e-07 reg 4.900000e+04 train accuracy: 0.295653 val accuracy: 0.315000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.296041 val accuracy: 0.318000\n",
      "lr 5.000000e-07 reg 5.100000e+04 train accuracy: 0.305122 val accuracy: 0.312000\n",
      "lr 5.000000e-07 reg 5.200000e+04 train accuracy: 0.310429 val accuracy: 0.317000\n",
      "lr 5.000000e-07 reg 5.300000e+04 train accuracy: 0.312286 val accuracy: 0.322000\n",
      "lr 5.000000e-07 reg 5.400000e+04 train accuracy: 0.304204 val accuracy: 0.324000\n",
      "lr 5.000000e-07 reg 5.500000e+04 train accuracy: 0.289694 val accuracy: 0.295000\n",
      "lr 5.000000e-07 reg 5.600000e+04 train accuracy: 0.290510 val accuracy: 0.313000\n",
      "lr 5.000000e-07 reg 5.700000e+04 train accuracy: 0.299163 val accuracy: 0.316000\n",
      "lr 5.000000e-07 reg 5.800000e+04 train accuracy: 0.301612 val accuracy: 0.314000\n",
      "lr 5.000000e-07 reg 5.900000e+04 train accuracy: 0.294653 val accuracy: 0.311000\n",
      "lr 7.000000e-07 reg 1.000000e+04 train accuracy: 0.350878 val accuracy: 0.357000\n",
      "lr 7.000000e-07 reg 1.100000e+04 train accuracy: 0.353510 val accuracy: 0.364000\n",
      "lr 7.000000e-07 reg 1.200000e+04 train accuracy: 0.335857 val accuracy: 0.356000\n",
      "lr 7.000000e-07 reg 1.300000e+04 train accuracy: 0.347102 val accuracy: 0.362000\n",
      "lr 7.000000e-07 reg 1.400000e+04 train accuracy: 0.342735 val accuracy: 0.365000\n",
      "lr 7.000000e-07 reg 1.500000e+04 train accuracy: 0.345143 val accuracy: 0.356000\n",
      "lr 7.000000e-07 reg 1.600000e+04 train accuracy: 0.342980 val accuracy: 0.348000\n",
      "lr 7.000000e-07 reg 1.700000e+04 train accuracy: 0.332980 val accuracy: 0.351000\n",
      "lr 7.000000e-07 reg 1.800000e+04 train accuracy: 0.328184 val accuracy: 0.331000\n",
      "lr 7.000000e-07 reg 1.900000e+04 train accuracy: 0.326265 val accuracy: 0.345000\n",
      "lr 7.000000e-07 reg 2.000000e+04 train accuracy: 0.330898 val accuracy: 0.345000\n",
      "lr 7.000000e-07 reg 2.100000e+04 train accuracy: 0.327796 val accuracy: 0.353000\n",
      "lr 7.000000e-07 reg 2.200000e+04 train accuracy: 0.329878 val accuracy: 0.343000\n",
      "lr 7.000000e-07 reg 2.300000e+04 train accuracy: 0.327735 val accuracy: 0.349000\n",
      "lr 7.000000e-07 reg 2.400000e+04 train accuracy: 0.314653 val accuracy: 0.337000\n",
      "lr 7.000000e-07 reg 2.500000e+04 train accuracy: 0.323776 val accuracy: 0.336000\n",
      "lr 7.000000e-07 reg 2.600000e+04 train accuracy: 0.321306 val accuracy: 0.337000\n",
      "lr 7.000000e-07 reg 2.700000e+04 train accuracy: 0.326204 val accuracy: 0.334000\n",
      "lr 7.000000e-07 reg 2.800000e+04 train accuracy: 0.325122 val accuracy: 0.334000\n",
      "lr 7.000000e-07 reg 2.900000e+04 train accuracy: 0.318673 val accuracy: 0.332000\n",
      "lr 7.000000e-07 reg 3.000000e+04 train accuracy: 0.328122 val accuracy: 0.337000\n",
      "lr 7.000000e-07 reg 3.100000e+04 train accuracy: 0.321367 val accuracy: 0.343000\n",
      "lr 7.000000e-07 reg 3.200000e+04 train accuracy: 0.312551 val accuracy: 0.326000\n",
      "lr 7.000000e-07 reg 3.300000e+04 train accuracy: 0.319102 val accuracy: 0.330000\n",
      "lr 7.000000e-07 reg 3.400000e+04 train accuracy: 0.307306 val accuracy: 0.319000\n",
      "lr 7.000000e-07 reg 3.500000e+04 train accuracy: 0.314551 val accuracy: 0.316000\n",
      "lr 7.000000e-07 reg 3.600000e+04 train accuracy: 0.301367 val accuracy: 0.298000\n",
      "lr 7.000000e-07 reg 3.700000e+04 train accuracy: 0.299837 val accuracy: 0.318000\n",
      "lr 7.000000e-07 reg 3.800000e+04 train accuracy: 0.303265 val accuracy: 0.328000\n",
      "lr 7.000000e-07 reg 3.900000e+04 train accuracy: 0.302408 val accuracy: 0.309000\n",
      "lr 7.000000e-07 reg 4.000000e+04 train accuracy: 0.302122 val accuracy: 0.329000\n",
      "lr 7.000000e-07 reg 4.100000e+04 train accuracy: 0.306469 val accuracy: 0.318000\n",
      "lr 7.000000e-07 reg 4.200000e+04 train accuracy: 0.297163 val accuracy: 0.311000\n",
      "lr 7.000000e-07 reg 4.300000e+04 train accuracy: 0.294163 val accuracy: 0.306000\n",
      "lr 7.000000e-07 reg 4.400000e+04 train accuracy: 0.300265 val accuracy: 0.306000\n",
      "lr 7.000000e-07 reg 4.500000e+04 train accuracy: 0.287735 val accuracy: 0.302000\n",
      "lr 7.000000e-07 reg 4.600000e+04 train accuracy: 0.305061 val accuracy: 0.316000\n",
      "lr 7.000000e-07 reg 4.700000e+04 train accuracy: 0.316367 val accuracy: 0.326000\n",
      "lr 7.000000e-07 reg 4.800000e+04 train accuracy: 0.300306 val accuracy: 0.321000\n",
      "lr 7.000000e-07 reg 4.900000e+04 train accuracy: 0.292796 val accuracy: 0.304000\n",
      "lr 7.000000e-07 reg 5.000000e+04 train accuracy: 0.292449 val accuracy: 0.297000\n",
      "lr 7.000000e-07 reg 5.100000e+04 train accuracy: 0.295367 val accuracy: 0.306000\n",
      "lr 7.000000e-07 reg 5.200000e+04 train accuracy: 0.307837 val accuracy: 0.304000\n",
      "lr 7.000000e-07 reg 5.300000e+04 train accuracy: 0.312592 val accuracy: 0.329000\n",
      "lr 7.000000e-07 reg 5.400000e+04 train accuracy: 0.298490 val accuracy: 0.315000\n",
      "lr 7.000000e-07 reg 5.500000e+04 train accuracy: 0.295571 val accuracy: 0.317000\n",
      "lr 7.000000e-07 reg 5.600000e+04 train accuracy: 0.287020 val accuracy: 0.298000\n",
      "lr 7.000000e-07 reg 5.700000e+04 train accuracy: 0.291102 val accuracy: 0.304000\n",
      "lr 7.000000e-07 reg 5.800000e+04 train accuracy: 0.285510 val accuracy: 0.297000\n",
      "lr 7.000000e-07 reg 5.900000e+04 train accuracy: 0.308898 val accuracy: 0.320000\n",
      "lr 9.000000e-07 reg 1.000000e+04 train accuracy: 0.343265 val accuracy: 0.360000\n",
      "lr 9.000000e-07 reg 1.100000e+04 train accuracy: 0.349204 val accuracy: 0.350000\n",
      "lr 9.000000e-07 reg 1.200000e+04 train accuracy: 0.341653 val accuracy: 0.362000\n",
      "lr 9.000000e-07 reg 1.300000e+04 train accuracy: 0.343653 val accuracy: 0.349000\n",
      "lr 9.000000e-07 reg 1.400000e+04 train accuracy: 0.341020 val accuracy: 0.340000\n",
      "lr 9.000000e-07 reg 1.500000e+04 train accuracy: 0.336061 val accuracy: 0.351000\n",
      "lr 9.000000e-07 reg 1.600000e+04 train accuracy: 0.333082 val accuracy: 0.346000\n",
      "lr 9.000000e-07 reg 1.700000e+04 train accuracy: 0.330102 val accuracy: 0.340000\n",
      "lr 9.000000e-07 reg 1.800000e+04 train accuracy: 0.332714 val accuracy: 0.352000\n",
      "lr 9.000000e-07 reg 1.900000e+04 train accuracy: 0.325224 val accuracy: 0.336000\n",
      "lr 9.000000e-07 reg 2.000000e+04 train accuracy: 0.328980 val accuracy: 0.326000\n",
      "lr 9.000000e-07 reg 2.100000e+04 train accuracy: 0.328388 val accuracy: 0.339000\n",
      "lr 9.000000e-07 reg 2.200000e+04 train accuracy: 0.330878 val accuracy: 0.358000\n",
      "lr 9.000000e-07 reg 2.300000e+04 train accuracy: 0.321755 val accuracy: 0.340000\n",
      "lr 9.000000e-07 reg 2.400000e+04 train accuracy: 0.308082 val accuracy: 0.325000\n",
      "lr 9.000000e-07 reg 2.500000e+04 train accuracy: 0.321510 val accuracy: 0.319000\n",
      "lr 9.000000e-07 reg 2.600000e+04 train accuracy: 0.308673 val accuracy: 0.337000\n",
      "lr 9.000000e-07 reg 2.700000e+04 train accuracy: 0.314776 val accuracy: 0.321000\n",
      "lr 9.000000e-07 reg 2.800000e+04 train accuracy: 0.311184 val accuracy: 0.316000\n",
      "lr 9.000000e-07 reg 2.900000e+04 train accuracy: 0.319184 val accuracy: 0.333000\n",
      "lr 9.000000e-07 reg 3.000000e+04 train accuracy: 0.313653 val accuracy: 0.324000\n",
      "lr 9.000000e-07 reg 3.100000e+04 train accuracy: 0.299755 val accuracy: 0.310000\n",
      "lr 9.000000e-07 reg 3.200000e+04 train accuracy: 0.321184 val accuracy: 0.346000\n",
      "lr 9.000000e-07 reg 3.300000e+04 train accuracy: 0.307000 val accuracy: 0.328000\n",
      "lr 9.000000e-07 reg 3.400000e+04 train accuracy: 0.297816 val accuracy: 0.305000\n",
      "lr 9.000000e-07 reg 3.500000e+04 train accuracy: 0.302306 val accuracy: 0.313000\n",
      "lr 9.000000e-07 reg 3.600000e+04 train accuracy: 0.305735 val accuracy: 0.323000\n",
      "lr 9.000000e-07 reg 3.700000e+04 train accuracy: 0.299184 val accuracy: 0.300000\n",
      "lr 9.000000e-07 reg 3.800000e+04 train accuracy: 0.299510 val accuracy: 0.314000\n",
      "lr 9.000000e-07 reg 3.900000e+04 train accuracy: 0.307388 val accuracy: 0.312000\n",
      "lr 9.000000e-07 reg 4.000000e+04 train accuracy: 0.304204 val accuracy: 0.317000\n",
      "lr 9.000000e-07 reg 4.100000e+04 train accuracy: 0.306388 val accuracy: 0.318000\n",
      "lr 9.000000e-07 reg 4.200000e+04 train accuracy: 0.297878 val accuracy: 0.317000\n",
      "lr 9.000000e-07 reg 4.300000e+04 train accuracy: 0.309694 val accuracy: 0.319000\n",
      "lr 9.000000e-07 reg 4.400000e+04 train accuracy: 0.312082 val accuracy: 0.324000\n",
      "lr 9.000000e-07 reg 4.500000e+04 train accuracy: 0.318633 val accuracy: 0.331000\n",
      "lr 9.000000e-07 reg 4.600000e+04 train accuracy: 0.293755 val accuracy: 0.298000\n",
      "lr 9.000000e-07 reg 4.700000e+04 train accuracy: 0.293592 val accuracy: 0.308000\n",
      "lr 9.000000e-07 reg 4.800000e+04 train accuracy: 0.301082 val accuracy: 0.313000\n",
      "lr 9.000000e-07 reg 4.900000e+04 train accuracy: 0.305816 val accuracy: 0.311000\n",
      "lr 9.000000e-07 reg 5.000000e+04 train accuracy: 0.303878 val accuracy: 0.304000\n",
      "lr 9.000000e-07 reg 5.100000e+04 train accuracy: 0.312204 val accuracy: 0.318000\n",
      "lr 9.000000e-07 reg 5.200000e+04 train accuracy: 0.274755 val accuracy: 0.295000\n",
      "lr 9.000000e-07 reg 5.300000e+04 train accuracy: 0.297408 val accuracy: 0.304000\n",
      "lr 9.000000e-07 reg 5.400000e+04 train accuracy: 0.289245 val accuracy: 0.304000\n",
      "lr 9.000000e-07 reg 5.500000e+04 train accuracy: 0.294898 val accuracy: 0.307000\n",
      "lr 9.000000e-07 reg 5.600000e+04 train accuracy: 0.281163 val accuracy: 0.291000\n",
      "lr 9.000000e-07 reg 5.700000e+04 train accuracy: 0.288000 val accuracy: 0.309000\n",
      "lr 9.000000e-07 reg 5.800000e+04 train accuracy: 0.291469 val accuracy: 0.306000\n",
      "lr 9.000000e-07 reg 5.900000e+04 train accuracy: 0.299980 val accuracy: 0.322000\n",
      "best validation accuracy achieved during cross-validation: 0.371000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 3e-7, 5e-7, 7e-7, 9e-7]\n",
    "regularization_strengths = [(j + 0.1 * i) * 1e4 for i in range(0, 10) for j in range(1, 6)]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "for reg in regularization_strengths:\n",
    "    for learning_rate in learning_rates:\n",
    "        softmax = Softmax()\n",
    "        loss_hist = softmax.train(X_train, y_train, learning_rate=learning_rate, reg=reg,\n",
    "                              num_iters=1500)\n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        training_acc = np.mean(y_train == y_train_pred)\n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        validation_acc = np.mean(y_val == y_val_pred)\n",
    "        if(validation_acc > best_val):\n",
    "            best_val = validation_acc\n",
    "            best_softmax = softmax\n",
    "        results[(learning_rate, reg)] = (training_acc, validation_acc)\n",
    "        print(reg)\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.364000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inline Question** - *True or False*\n",
    "\n",
    "It's possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "*Your answer*:\n",
    "\n",
    "*Your explanation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
